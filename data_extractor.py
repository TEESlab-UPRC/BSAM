"""
This module handles data extraction & visualization from the saved files generated by the application
"""

import dataio
import pandas
import numpy
import datetime
import matplotlib
import matplotlib.pyplot

# set plot style
matplotlib.pyplot.style.use('ggplot')
#matplotlib.pyplot.style.use('bmh')
#matplotlib.pyplot.style.use('seaborn-darkgrid')
#matplotlib.pyplot.style.use('fivethirtyeight')

def load_market(path=None, zipped=False):
    """
    Loads a saved (pickled) market object
    """
    if path == None:
        # load the market object saved at the default location
        market = dataio.load_object(zipped=zipped)
    else:
        market = dataio.load_object(path,zipped=zipped)
    return market


def get_market_results(market,cost_benefits_calculator,cost_benefit_calculation_data):
    """
    Do data extraction from the market object to get results pertinent to the electricity market,
    The aggregation of the results varies, but it is specified below.
    Specifically extracted data include:
    # market.saved_daily_marginal_costs [cost,day] (daily) - SMP
    # market.fuel.water_price [water_price, day] (monthly) - Water prices
    # market.single_plant_agents[index].taken_actions [action_index, explore] (daily) - Taken agent actions
    # market.single_plant_agents[index].plant.saved_online_data [[online_data,day],.....] (daily) - Utilization for each plant
    # market.fuel.wind_scenario dataframe: each row a date, each column and hour, cells contain total produced power (hourly) - Wind generation forecast
    # market.fuel.pv_scenario dataframe: each row a date, each column and hour, cells contain total produced power (hourly) - PV generation forecast
    # market.demand dataframe: columns=[day,hour,demand], each row a different hour (hourly) - Demand forecast
    """
    # get the index as datetime
    daterange_index = pandas.date_range(start=market.fuel.calculated_smp.index[0], end=market.fuel.calculated_smp.index[-1], freq='H')

    # get the columns
    columns = [[],[]]
    for agent in market.single_plant_agents:
        columns[0].append(agent.plant.name)
        columns[1].append(agent.plant.kind)

    # create the df after adding indices for solar, wind and res exports
    columns[0].extend(['solar','wind_onshore','wind_offshore','res_exports','biomass_cofiring'])
    columns[1].extend(['solar','wind_onshore','wind_offshore','res_exports','biomass_cofiring'])

    generation = pandas.DataFrame(0,index=daterange_index,columns=pandas.MultiIndex.from_arrays(columns,names=['plant_name','plant_kind']))

    # populate it with the generators we use for uc
    for agent in market.single_plant_agents:
        saved_power_data = agent.plant.saved_online_data.loc[:,'power']
        if 24 in agent.plant.saved_online_data.loc[:,'power'].index.get_level_values(1):
            saved_power_data = agent.plant.saved_online_data.loc[:,'power'].drop(24,level=1)
        saved_power_data.index = daterange_index
        generation.loc(axis=1)[agent.plant.name,agent.plant.kind] = saved_power_data
        # also handle biomass co-firing. need to do it on a yearly basis
        if agent.plant.name in market.generators_biomass_cofiring.columns:
            for year in market.generators_biomass_cofiring.index:
                if market.generators_biomass_cofiring.loc[year,agent.plant.name] > 0:
                    yearly_biomass_power = saved_power_data.loc[datetime.datetime(year,1,1,0):datetime.datetime(year,12,31,23)] * market.generators_biomass_cofiring.loc[year,agent.plant.name]
                    # this is quirky because pandas does not understand addition over the correct axis
                    generation.loc[datetime.datetime(year,1,1,0):datetime.datetime(year,12,31,23),'biomass_cofiring'] = generation.loc[datetime.datetime(year,1,1,0):datetime.datetime(year,12,31,23),'biomass_cofiring'].add(yearly_biomass_power,axis=0).values
    # this was the generated power of the generators we use for uc
    # we need to add to that the intermittent RES generation
    # add the wind, solar & imports power produced - these have a quirky format that needs to be changed to simple stacked to correctly fit
    generation.loc[:,'solar'] = market.fuel.pv_scenario.set_index('datetime').loc[generation.index[0]:generation.index[-1]].stack().values
    generation.loc[:,'wind_onshore'] = market.fuel.wind_onshore_scenario.set_index('datetime').loc[generation.index[0]:generation.index[-1]].stack().values
    generation.loc[:,'wind_offshore'] = market.fuel.wind_offshore_scenario.set_index('datetime').loc[generation.index[0]:generation.index[-1]].stack().values

    # and add any res_exports that happened if applicable
    if market.res_exports_plant is not bool:
        res_exports_power = market.res_exports_plant.saved_online_data.loc[:,'power']
        if 24 in market.res_exports_plant.saved_online_data.loc[:,'power'].index.get_level_values(1):
            res_exports_power = market.res_exports_plant.saved_online_data.loc[:,'power'].drop(24,level=1)
        generation.loc[:,'res_exports'] = res_exports_power.values
    # remove res exports from res generation, by appropriately scaling down the generation
    index_res_exports = generation.loc[:,'res_exports'][generation.loc[:,'res_exports']>0].dropna().index
    res_gen_scale_coefficient = 1 - generation.loc[index_res_exports,'res_exports'].div(generation.loc[index_res_exports,'solar'].join(generation.loc[index_res_exports,'wind_onshore']).join(generation.loc[index_res_exports,'wind_offshore']).sum(axis=1),axis=0)
    generation.loc[index_res_exports,'solar'] = generation.loc[index_res_exports,'solar'].values * res_gen_scale_coefficient.values
    generation.loc[index_res_exports,'wind_onshore'] = generation.loc[index_res_exports,'wind_onshore'].values * res_gen_scale_coefficient.values
    generation.loc[index_res_exports,'wind_offshore'] = generation.loc[index_res_exports,'wind_offshore'].values * res_gen_scale_coefficient.values

    # at this point generation total should equal demand. if not stop and complain
    # Note that for this to be correct, biomass_cofiring must be subtracted, as it is estimated & on top of other types
    # Also, res_exports_power must be subtracted as it was added on top of the total but not included in the demand
    if not numpy.isclose(generation.sum().sum() - generation.loc[:,"biomass_cofiring"].sum().sum() - generation.loc[:,"res_exports"].sum().sum(), market.demand.set_index('day').loc[generation.index[0]:generation.index[-1],'demand'].sum()):
        print('generation totals do not match! starting debugger')
        import ipdb;ipdb.set_trace()

    # group by the generation types
    generation = generation.groupby(axis=1,level=1).sum()
    # apply any existing limits to cofiring generation as required increasing coal generation by the same amounts
    # if no limit exists, the cofiring adjustment will be 1
    if 'biomass_cofiring' in generation.columns and 'hard_coal' in generation.columns:
        total_cofiring = generation.loc[:,'biomass_cofiring'].resample('A').sum()
        # if a limit exists, adjust the percents correctly using a cofiring_percent_adjustment percentile variable to not allow more cofiring than described
        if cost_benefit_calculation_data.loc['biomass_cofiring_res_max_yearly_generation','value'] >= 0:
            cofiring_percent_adjustment = (cost_benefit_calculation_data.loc['biomass_cofiring_res_max_yearly_generation','value']/total_cofiring).clip(0,1)
            cofiring_percent_adjustment.index = numpy.arange(cofiring_percent_adjustment.index[0].year,cofiring_percent_adjustment.index[-1].year+1)
            # apply the adjustments year by year
            for year in cofiring_percent_adjustment.index:
                adjusted_yearly_amount = generation.loc[datetime.datetime(year,1,1,0):datetime.datetime(year,12,31,23),'biomass_cofiring'] * (1 - cofiring_percent_adjustment[year])
                generation.loc[datetime.datetime(year,1,1,0):datetime.datetime(year,12,31,23),'biomass_cofiring'] -= adjusted_yearly_amount
                generation.loc[datetime.datetime(year,1,1,0):datetime.datetime(year,12,31,23),'hard_coal'] += adjusted_yearly_amount
        # also, if cofiring takes place after subsidy expiry, adjust the generation further as needed
        if cost_benefit_calculation_data.loc['biomass_cofiring_res_max_yearly_generation_after_subsidy_expiry','value'] > 0:
            # get the subsidized percentages for cofiring and reduce the generation if needed
            total_cofiring = generation.loc[:,'biomass_cofiring'].resample('A').sum().to_frame()
            total_cofiring.index = [date.year for date in total_cofiring.index]
            subsidized_capacities_percents_cofiring = cost_benefits_calculator.calculate_subsidized_percentages(market.valid_years_to_model,cost_benefit_calculation_data.loc['biomass_cofiring_res_subsidy_start','value'],cost_benefit_calculation_data.loc['biomass_cofiring_res_subsidy_duration','value'],cost_benefit_calculation_data.loc['all_subsidies_expiry','value'],total_cofiring)
            for year in total_cofiring.index:
                adjusted_yearly_amount = generation.loc[datetime.datetime(year,1,1,0):datetime.datetime(year,12,31,23),'biomass_cofiring'] * (1 - subsidized_capacities_percents_cofiring.loc[year,'subsidized'])
                generation.loc[datetime.datetime(year,1,1,0):datetime.datetime(year,12,31,23),'biomass_cofiring'] -= adjusted_yearly_amount
                generation.loc[datetime.datetime(year,1,1,0):datetime.datetime(year,12,31,23),'hard_coal'] += adjusted_yearly_amount

    # add the percentile values of everything to the df
    for generation_type in generation.columns:
        generation_percentile_name = generation_type + '_%'
        if generation_type not in ['res_exports']:
            generation_percentile_values = generation.loc[:,generation_type].divide(market.demand.set_index('day').loc[generation.index[0]:generation.index[-1],'demand'].values).multiply(100).values
        elif generation_type in ['res_exports']:
            sum_res = generation.loc[:,'solar'].values + \
                        generation.loc[:,'wind_onshore'].values + \
                        generation.loc[:,'wind_offshore'].values + \
                        generation.loc[:,'res_exports'].values
            generation_percentile_values = (generation.loc[:,'res_exports'].values / sum_res) * 100
        generation.loc[:,generation_percentile_name] = generation_percentile_values

    # also add demand, 'real' smp, 'calculated smp', water price, real_nat gas share and calculated natural gas shares
    # to do so, also rename the dataframe
    results = generation
    # demand is easy. just add the column
    results.loc[:,'demand'] = market.demand.set_index('day').loc[generation.index[0]:generation.index[-1],'demand'].values
    # real smp is monthly... first convert to hourly (reindexing to the daterange we need and handling gaps) and then add
    real_smp = market.fuel.smp_data.resample('H').ffill().reindex(daterange_index).ffill()
    results.loc[:,'real_smp'] = real_smp.values
    # calculated smp is easy. just add the col
    results.loc[:,'calculated_smp'] = market.fuel.calculated_smp.loc[:,'hourly_smp'].values
    # water price needs greek data to get handled correctly. if non existent, set it to nan
    # if existent, reindex to an hourly resolution from monthly
    if not market.fuel.water_price.empty:
        results.loc[:,'water_price']=market.fuel.water_price.dropna().loc[:,'actual_general_price'].reindex(results.index).ffill()
    # real nat gas share is monthly. just resample and add
    real_nat_gas_share = market.fuel.nat_gas_contribution.resample('H').ffill().reindex(daterange_index).ffill()
    results.loc[:,'real_nat_gas_share'] = real_nat_gas_share.values
    # finally calculate the actual nat gas share by dividing the demand by the nat gas cols
    calculated_nat_gas_share = results.loc[:,'nat-gas-ccgt'].add(results.loc[:,'nat-gas-ocgt']).add(results.loc[:,'nat-gas-st']).divide(results.loc[:,'demand'])
    results.loc[:,'calculated_nat_gas_share'] = calculated_nat_gas_share.values
    return results


def remove_zero_columns(results, columns):
    """
    Checks columns given for plot and if they are at least at one point non-zero, returns them
    Thus columns that always stay zero are excluded
    """
    final_columns = []
    for column in columns:
        if column in results.columns and any(results[column]) and results[column].sum() > 0:
            final_columns.append(column)
    return final_columns


def transform_data_resolution(results,data_temporal_resolution,upsample):
    """
    Transform the daily data in results for easier visualization
    This is done via pandas resampling, though only specific drequencies are allowed
    W means weekly (at its end)
    M means monhtly (at its end)
    Q means quarter (at its end)
    A means yearly (at its end)
    5A means 5-yearly (at its end)
    """
    allowed_resolutions = ['W','M','Q','A','5A']
    # first resample to the resolution required
    if data_temporal_resolution in allowed_resolutions:
        results = results.resample(data_temporal_resolution).mean()
    # and then upsample (backfilling) to daily, so now there will be mean values for the periods in question
    if upsample:
        results = results.resample('D').bfill()
    return results


def plot_market_results(results,figures,save_results,save_folder,save_path,data_temporal_resolution='M',show_plots=True,market_plots_regression=True):
    """
    Plots electricity market extracted results
    figures is a list containing one or more of the following options:
    # 'electricity_mix',
    # 'prices',
    # 'demand_and_electricity_mix',
    # 'res_production',
    # 'thermal_vs_water_vs_res'
    # 'virtual_production'
    # 'calculated_smp_vs_real'
    # 'calculated_nat_gas_contrib_vs_real'

    Also, this list can contain custom plotting specifications, if the elements are lists
    each containing the desired column names (str) of the results object that we want to plot
    """
    # change the data temporal resolution if needed
    results = transform_data_resolution(results,data_temporal_resolution,upsample=True)

    to_select = []
    for figure_type in figures:
        axis_1_name = ''
        axis_2_name = ''
        columns_axis_2 = []

        if figure_type == 'demand_and_electricity_mix':
            columns_axis_1 = ['demand','nuclear','hard_coal','lignite-st','nat-gas-st','nat-gas-ccgt','biomass','waste','nat-gas-occgt','hydro','wind_onshore','wind_offshore','solar','virtual','imports']
            axis_1_name = 'Energy (MWh)'

        elif figure_type == 'electricity_mix':
            columns_axis_1 = ['nuclear','hard_coal','lignite-st','nat-gas-st','nat-gas-ccgt','biomass','waste','nat-gas-occgt','hydro','wind_onshore','wind_offshore','solar','virtual','imports','res_exports']
            axis_1_name = 'Energy (MWh)'

        elif figure_type == 'electricity_mix_percentages':
            columns_axis_1 = ['nuclear_%','hard_coal_%','lignite-st_%','nat-gas-st_%','nat-gas-ccgt_%','biomass_%','waste_%','nat-gas-occgt_%','hydro_%','wind_onshore_%','wind_offshore_%','solar_%','virtual_%','imports_%','res_exports_%']
            axis_1_name = 'Energy produced %'

        elif figure_type == 'electricity_mix_percentages_no_imports':
            columns_axis_1 = ['nuclear_%','hard_coal_%','lignite-st_%','nat-gas-st_%','nat-gas-ccgt_%','biomass_%','waste_%','nat-gas-occgt_%','hydro_%','wind_onshore_%','wind_offshore_%','solar_%','virtual_%','res_exports_%']
            axis_1_name = 'Energy produced %'

        elif figure_type == 'electricity_mix_no_coal_no_gas_cc':
            columns_axis_1 = ['nuclear','biomass','waste','nat-gas-occgt','hydro','wind_onshore','wind_offshore','solar','virtual','imports','res_exports']
            axis_1_name = 'Energy (MWh)'

        elif figure_type == 'electricity_mix_no_coal_no_gas_cc_percentages':
            columns_axis_1 = ['nuclear_%','biomass_%','waste_%','nat-gas-occgt_%','hydro_%','wind_onshore_%','wind_offshore_%','solar_%','virtual_%','imports_%','res_exports_%']
            axis_1_name = 'Energy produced %'

        elif figure_type == 'prices':
            columns_axis_1 = ['calculated_smp','actual_system_price','hydro_price']
            axis_1_name = 'Prices (E/MWh)'

        elif figure_type == 'res_production':
            columns_axis_1 = ['hydro','wind_onshore','wind_offshore','solar','biomass_cofiring','res_exports']
            axis_1_name = 'Energy (MWh)'

        elif figure_type == 'thermal_vs_hydro_vs_non_thermal_res':
            results['thermal'] = results['nuclear']+results['hard_coal']+results['lignite-st']+results['nat-gas-st']+results['nat-gas-ccgt']+results['biomass']+results['nat-gas-occgt']+results['waste']
            results['res'] = results['wind_onshore']+results['wind_offshore']+results['solar']
            columns_axis_1 = ['thermal','res','hydro']
            axis_1_name = 'Energy (MWh)'

        elif figure_type == 'thermal_vs_hydro_vs_res_percentage':
            results['thermal_percentage'] = results['nuclear_%']+results['hard_coal_%']+results['lignite-st_%']+results['nat-gas-st_%']+results['nat-gas-ccgt_%']+results['biomass_%']+results['waste_%']+results['nat-gas-occgt_%']
            results['res_percentage'] = results['wind_onshore_%']+results['wind_offshore_%']+results['solar_%']
            columns_axis_1 = ['thermal_percentage','res_percentage','hydro_%']
            axis_1_name = 'Energy produced %'

        elif figure_type == 'thermal_vs_hydro_vs_non_thermal_res_vs_imports':
            results['thermal'] = results['nuclear']+results['hard_coal']+results['lignite-st']+results['nat-gas-st']+results['nat-gas-ccgt']+results['biomass']+results['nat-gas-occgt']+results['waste']
            results['res'] = results['wind_onshore']+results['wind_offshore']+results['solar']
            columns_axis_1 = ['thermal','res','hydro','imports']
            axis_1_name = 'Energy (MWh)'

        elif figure_type == 'thermal_vs_hydro_vs_non_thermal_res_vs_imports_percentage':
            results['thermal_percentage'] = results['nuclear_%']+results['hard_coal_%']+results['lignite-st_%']+results['nat-gas-st_%']+results['nat-gas-ccgt_%']+results['biomass_%']+results['nat-gas-occgt_%']+results['waste_%']
            results['res_percentage'] = results['wind_onshore_%']+results['wind_offshore_%']+results['solar_%']
            columns_axis_1 = ['thermal_percentage','res_percentage','hydro_%','imports_%']
            axis_1_name = 'Energy produced %'

        elif figure_type == 'virtual_production':
            columns_axis_1 = ['virtual']
            axis_1_name = 'Energy (MWh)'
            columns_axis_2 = [['virtual_%'],['k']]
            axis_2_name = 'Energy produced %'

        elif figure_type == 'imports_exports':
            columns_axis_1 = ['imports','res_exports']
            axis_1_name = 'Energy (MWh)'
            columns_axis_2 = [['imports_%','res_exports_%'],['k--','b--']]
            axis_2_name = 'Energy produced %'

        elif figure_type == 'calculated_smp_vs_real':
            columns_axis_1 = ['real_smp','calculated_smp']
            axis_1_name = 'Prices (E/MWh)'

        elif figure_type == 'calculated_nat_gas_contrib_vs_real':
            columns_axis_1 = ['real_nat_gas_share','calculated_nat_gas_share']
            axis_1_name = 'Natural gas share %'

        elif figure_type == 'everything':
            columns_axis_1 = ['demand','nuclear','hard_coal','lignite-st','nat-gas-st','nat-gas-ccgt','biomass','waste',\
                            'nat-gas-occgt','hydro','wind_onshore','wind_offshore','solar','virtual','imports','hydro','res_exports']
            axis_1_name = 'Energy (MWh)'
            columns_axis_2 = [['calculated_smp'],['k--']]
            axis_2_name = 'Prices (E/MWh)'

        else:
            # this gives the possibility to plot custom selected columns
            columns_axis_1 = figure_type[0]
            columns_axis_2 = figure_type[1]
            figure_type = 'custom'

        # filter zero cols unless for figtypes where we assume that zero cols are not desirable (meaningless)
        if figure_type not in ['virtual_production','imports_exports','custom']:
            columns_axis_1 = remove_zero_columns(results,columns_axis_1)
        # and append the selection to the selected plots
        to_select.append([columns_axis_1,axis_1_name,columns_axis_2,axis_2_name,figure_type])

    # get the label to show as yearly dates
    xticks=[date for date in results.index if date.day == 1 and date.month==1]

    for selection in to_select:
        # do a check & ensure that rows in selection[0] also exist in results - this could be done better using a.all(b)
        columns_to_plot_exist = True
        for column_to_plot in selection[0]:
            if column_to_plot not in results.columns:
                columns_to_plot_exist = False
                print ('Warning, a column to plot (',column_to_plot,') does not exist. Skipping..')

        if columns_to_plot_exist:
            figure = matplotlib.pyplot.figure()
            ax = figure.add_subplot(111)
            ax.set_ylabel(selection[1])
            ax.grid(True)
            data_to_plot = results[selection[0]]
            # create trendline as required
            if market_plots_regression:
                data_to_plot = create_trendline(data_to_plot)
            plot = data_to_plot.plot(ax=ax, legend=True)
            plot.legend(loc = "upper right", ncol=5, fancybox=True, shadow=True)

            if any(selection[2]):
                secondary_data_to_plot = results[selection[2][0]]
                # create trendline as required
                if market_plots_regression:
                    secondary_data_to_plot = create_trendline(secondary_data_to_plot)
                # if we have two axes, add the second
                ax_2 = ax.twinx()
                ax_2.set_ylabel(selection[3])
                # and if there was a specified style, use it
                if selection[2][1]:
                    plot_2 = secondary_data_to_plot.plot(ax=ax_2, legend=True, style=selection[2][1])
                else:
                    plot_2 = secondary_data_to_plot.plot(ax=ax_2, legend=True)
                plot_2.legend(loc = "lower right", fancybox=True, shadow=True)
            # save the figure if asked to

            if save_results:
                root_folder_path = save_path+save_folder
                dataio.create_folder(root_folder_path)
                folder_path = save_path+save_folder+'/market_charts/'
                dataio.create_folder(folder_path)
                figure_saver(folder_path,figure,selection[4])

    # plot
    if show_plots:
        matplotlib.pyplot.show()

def create_trendline(data_to_plot,poly_degree=2):
    """
    Fits the data within the data_to_plot dataframe into a polynomial function & return a projection based on that
    """
    # convert index to numeric
    num_index = pandas.to_numeric(data_to_plot.dropna().index)
    # get the polynomial fits for every column into a dataframe
    polyfit = numpy.polyfit(num_index,data_to_plot.dropna(),deg=poly_degree)
    polyfit = pandas.DataFrame(polyfit,columns=data_to_plot.columns)

    # create a new DF with the fitted_data
    fitted_data = pandas.DataFrame(index=data_to_plot.index,columns=data_to_plot.columns)
    fitted_data_index = pandas.to_numeric(data_to_plot.index)
    # and populate it with the predictions
    for column in fitted_data.columns:
        prediction = numpy.poly1d(polyfit[column].values)(fitted_data_index)
        fitted_data.loc[:,column] = prediction
    return fitted_data

def get_agent_results(market):
    """
    Extract results related to the agents behaviour from the results file.
    To do so, create a dataframe for each agent, extracting for each hour:
    # the action selected
    # the power produced
    # the smp
    # the profit
    # the exploit frequency
    """
    # create a hierarchical dataframe to store all agent data, the index will be the day,
    # while for each agent the releval columns will be action,exploit_status,profit,power_produced, plus the agent index and kind (3-lvl index)
    general_saved_data = market.fuel.calculated_smp.loc[:,'daily_smp'].resample('D').mean().to_frame()
    # make the column multiindex to conform with later data
    general_saved_data.columns = pandas.MultiIndex.from_product([[-1],['smp'],general_saved_data.columns],names=['agent_index','plant_kind','agent_data'])

    for agent_index,agent in enumerate(market.single_plant_agents):
        # saved_online data contains datetime + power,action
        agent_saved_data = agent.taken_actions
        # get the produced power of the plant aggregated daily & concat with the above df. using inner join so that index conflicts are skipped (non-matching indices dropped)
        agent_saved_data = pandas.concat([agent_saved_data,agent.plant.saved_online_data.groupby(level=0).sum().loc[:,'power']],axis=1,join='inner')
        # also get the carbon emissions & their cost
        agent_saved_data = pandas.concat([agent_saved_data,agent.plant.saved_online_data.groupby(level=0).sum().loc[:,'total_emissions']],axis=1,join='inner')
        agent_saved_data = pandas.concat([agent_saved_data,agent.plant.saved_online_data.groupby(level=0).sum().loc[:,'total_carbon_cost']],axis=1,join='inner')
        # make it multiindex
        columns_index = pandas.MultiIndex.from_product([[agent_index],[agent.plant.kind],agent_saved_data.columns],names=['agent_index','plant_kind','agent_data'])
        agent_saved_data.columns = columns_index

        # and concat with general_saved_data
        general_saved_data = pandas.concat([general_saved_data,agent_saved_data],axis=1,join='inner')


    # sort the multiindex to allow easy slicing ! ! ! dafuq?
    general_saved_data.sort_index(axis=1,inplace=True)

    # rename the indices with the correct plant names
    # first get all the correct names in a list
    new_l0_columns = []
    for position,plant_index in enumerate(general_saved_data.columns.levels[0]):
        plant_name = plant_index
        if plant_index >= 0:
            plant_name = market.single_plant_agents[plant_index].plant.name
        new_l0_columns.append(plant_name)
    # replace the l0 columns
    general_saved_data.columns.set_levels(new_l0_columns,level=0,inplace=True)
    # and enforce floats rather than objects
    general_saved_data = general_saved_data.astype('float')
    return general_saved_data


def plot_agent_results(results, show_plots, save_folder, save_path, figures=['actions'], save_results=False):
    """
    Plots agents extracted results. Some plots are
    1. actions:                 action distribution averages
    2. exploit:                 exploit distribution averages
    2. actions_per_plant_kind:  mean & st.dev of actions per plant kind
    3. profit_per_action:       mean & st.dev. of profit per action selected
    4. profit_per_plant_kind:   average profit per plant type
    Only agents that decided on an action are handled (hydro & virtual plants are excluded)
    """

    # results is a multiindex dataframe
    # access data from results like this:
    # general_saved_data.xs((1,'lignite-st','profit'),axis=1)
    # general_saved_data.loc(axis=1)[:,'lignite-st','power']

    # for agent results, we need to reject all plant kinds that are not choosing an action (virtual,imports,hydro)
    results = results.drop(['hydro','virtual','imports'],axis=1,level=1)
    # here save the selected plots for plotting later on
    to_select = []
    for figure_type in figures:
        axis_1_name = ''
        plot_kind = 'bar'

        if figure_type == 'actions':
            # drop everything other than actions
            new_plot = results.loc(axis=1)[:,:,'action']
            # flatten dataframe (will create duplicate named columns)
            new_plot.columns = new_plot.columns.get_level_values(2)
            # and get the frequency of each action by using value_counts after unravelling new_plot (making it a series)
            new_plot = pandas.value_counts(new_plot.values.ravel(),normalize=True).sort_index()
            new_plot.name = 'action_index'
            axis_1_name = 'action_frequency'

        elif figure_type == 'exploit':
            # drop everything other than exploit status
            new_plot = results.loc(axis=1)[:,:,'exploit_status']
            # flatten dataframe (will create duplicate named columns)
            new_plot.columns = new_plot.columns.get_level_values(2)
            # and get the frequency of each action by using value_counts after unravelling new_plot (making it a series)
            new_plot = pandas.value_counts(new_plot.values.ravel(),normalize=True).sort_index()
            new_plot.name = 'exploit_status'
            axis_1_name = 'exploit_frequency'

        elif figure_type == 'actions_per_plant_kind':
            # drop everything other than actions
            new_plot = results.loc(axis=1)[:,:,'action']
            matplotlib.pyplot.show()
            # group by pland kind and only keep the mean & stddev values
            new_plot = pandas.concat([new_plot.groupby(level=1,axis=1).mean().mean(),new_plot.groupby(level=1,axis=1).std().std()],axis=1)
            new_plot.columns = ['mean selected action index','standard_deviation']
            axis_1_name = 'mean selected action index'

        elif figure_type == 'profit_per_action':
            # drop everything other than action & profit
            new_data = results.loc(axis=1)[:,:,['action','profit']]
            # drop those not bidding in LSPI
            new_data = new_data.drop(['hydro', 'imports', 'virtual'],axis=1,level=1)
            # concat all rows
            # start with an empty df (but correct index & cols)
            new_plot = pandas.DataFrame(columns = ['action','profit'])
            for plant_index in new_data.columns.get_level_values(0):
                if not new_data.loc[:,[plant_index]].empty:
                    # get and flatten the data to be concatted
                    to_concat = new_data.loc[:,plant_index]
                    to_concat.columns = to_concat.columns.get_level_values(1)
                    new_plot = pandas.concat([new_plot,to_concat])
            # of course the index of new_plot is incorrect, but is also irrelevant
            # so, just get the mean profit_per_action
            new_plot = new_plot.groupby('action').mean()
            new_plot.index.name = 'action_index'
            axis_1_name = 'mean profit'

        elif figure_type == 'profit_per_plant_kind':
            # drop everything other than profit
            new_plot = results.loc(axis=1)[:,:,['profit']]
            new_plot = new_plot.groupby(level=1,axis=1).mean()
            new_plot = new_plot.mean()
            new_plot.name = 'plant kind'
            axis_1_name = 'mean profit'

        else:
            print('Incorrect agent data plot type specified. Entering debug mode')
            import ipdb;ipdb.set_trace()

        # and append the selection to the selected plots
        to_select.append([axis_1_name,new_plot,plot_kind,figure_type])


    for selection in to_select:
        figure = matplotlib.pyplot.figure()
        ax = figure.add_subplot(111)
        ax.set_ylabel(selection[0])
        ax.grid(True)
        if selection[3] == 'actions_per_plant_kind':
            plot = selection[1].iloc[:,0].plot(ax=ax,legend=True, kind=selection[2],yerr=selection[1].iloc[:,1])
        else:
            plot = selection[1].plot(ax=ax, legend=True, kind=selection[2])
        plot.legend(loc = "upper right", ncol=5, fancybox=True, shadow=True)
        if save_results:
            root_folder_path = save_path+save_folder
            dataio.create_folder(root_folder_path)
            folder_path = save_path+save_folder+'/agent_charts/'
            dataio.create_folder(folder_path)
            figure_saver(folder_path,figure,selection[3])

    # and plot if needed
    if show_plots:
        matplotlib.pyplot.show()
    else:
        matplotlib.pyplot.clf()
        matplotlib.pyplot.close('all')

def figure_saver(save_path,figure,figure_type):
    """
    Used to save the generated figures
    """
    # make this eps for vector gfx (much better quality & lower size) if we need it
    # keep in mind that we need illustrator/inkscape/other vector gfx editor for eps images
    img_format = 'png'
    path = save_path + figure_type + '.' + img_format
    # we want images of size quadruple HD (1080x1024)x4 = 4320 x 4096
    # but we want the fontsize to not be tiny (half the default is ok)
    # so dpi is made 300 & figuresize (14.4,13.65)
    figure.set_size_inches((14.4,13.65))
    figure.tight_layout()
    figure.savefig(path, format=img_format, dpi=300)

def generate_market_tables(market,results,save_results,save_path,save_folder,data_temporal_resolution):
    """
    Creates table data for market results so that they will be easy to assess
    If save_tables == True, it saves them as csv files in the path entered
    """
    # unpack the results
    market_results = results['market_results_data']
    agent_results = results['agent_results_data']
    # for everything other than profitability, we can just upsample the results and keep the needed data
    # these should be mean values
    market_mean_cols = ['actual_system_price','calculated_smp','water_price','calculated_nat_gas_share','nuclear_%','hard_coal_%','lignite-st_%','nat-gas-st_%','nat-gas-ocgt_%','nat-gas-ccgt_%','biomass_%',\
                        'waste_%','nat-gas-occgt_%','biomass_cofiring_%','hydro_%','wind_onshore_%','wind_offshore_%','solar_%','virtual_%','imports_%','res_exports_%']
    market_mean_cols = [col for col in market_results if col in market_mean_cols]
    # these should be aggregated
    market_aggregate_cols = ['demand','nuclear','hard_coal','lignite-st','nat-gas-st','nat-gas-ccgt','biomass','waste','nat-gas-ocgt','biomass_cofiring','hydro',\
                        'wind_onshore','wind_offshore','solar','virtual','imports','res_exports']
    market_aggregate_cols = [col for col in market_results if col in market_aggregate_cols]
    # do the resampling
    market_results_resampled_mean = market_results.loc[:,market_mean_cols].resample(data_temporal_resolution).mean()
    market_results_resampled_mean.index.name = 'year'
    market_results_resampled_aggregated = market_results.loc[:,market_aggregate_cols].resample(data_temporal_resolution).sum()
    market_results_resampled_aggregated.index.name = 'year'
    # the dropna would also drop things from the mean col even on needed years. thus we do not drop there, using an inner join instead
    market_results_resampled = pandas.merge(market_results_resampled_aggregated,market_results_resampled_mean,left_index=True,right_index=True,how='inner')
    # for plant profitability, we just need to do the same to the agent_results
    agent_mean_cols = ['action', 'daily_smp']
    agent_aggregate_cols = ['power', 'total_emissions', 'total_carbon_cost', 'profit']
    if data_temporal_resolution == 'H':
        agent_results_resampled_mean = agent_results.loc(axis=1)[:,:,agent_mean_cols].resample(data_temporal_resolution).mean().ffill()
        agent_results_resampled_aggregated = agent_results.loc(axis=1)[:,:,agent_aggregate_cols].resample(data_temporal_resolution).sum().ffill()
    else:
        agent_results_resampled_mean = agent_results.loc(axis=1)[:,:,agent_mean_cols].resample(data_temporal_resolution).mean()
        agent_results_resampled_aggregated = agent_results.loc(axis=1)[:,:,agent_aggregate_cols].resample(data_temporal_resolution).sum().dropna()
    agent_results_resampled_mean.index.name = 'year'
    agent_results_resampled_aggregated.index.name = 'year'
    # merge the tables
    agent_results_resampled = pandas.merge(agent_results_resampled_aggregated,agent_results_resampled_mean,left_index=True,right_index=True,how='inner')

    #also get profitability
    profitability = agent_results_resampled_aggregated.loc(axis=1)[:,:,'profit']

    # finally, get closing decisions
    closing_down_decisions = pandas.DataFrame(columns=['closing_down_decision','date'])
    for agent in market.single_plant_agents:
        closing_down_decisions.loc[agent.plant.name] = agent.plant.close_down

    if save_results:
        root_folder_path = save_path+save_folder
        dataio.create_folder(root_folder_path)
        # and save the results in a multisheet excel
        writer = pandas.ExcelWriter(root_folder_path+'/market_tables.xlsx')
        market_results_resampled_mean.to_excel(writer,'market_results_mean')
        market_results_resampled_aggregated.to_excel(writer,'market_results_aggregated')
        agent_results_resampled_mean.to_excel(writer,'agent_results_mean')
        agent_results_resampled_aggregated.to_excel(writer,'agent_results_aggregated')
        closing_down_decisions.to_excel(writer,'closing_down_decisions')
        profitability.to_excel(writer,'profitability')
        market.fuel.calculated_smp.to_excel(writer,'hourly_smp')
        writer.save()
    return [market_results_resampled_mean,market_results_resampled_aggregated,agent_results_resampled_mean,agent_results_resampled_aggregated]
