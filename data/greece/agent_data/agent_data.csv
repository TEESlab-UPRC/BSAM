index,data1,data2,data3,data4
reward_normalization_factor,1000000
lspi_exploration_factor,1
lspi_discount_factor,0.9
lspi_epsilon,1
lspi_delta,0.1
lspi_max_iterations,100
lspi_state_dimensions,3
lspi_state_scale_per_dimension,10000,1,1,100
lspi_poly_type,1
lspi_poly_degree,3
lspi_init_weights,1
lspi_update_frequency,10
dqn_discount_factor,0.9
dqn_update_frequency,30
dqn_layer_size,12
dqn_layer_kernel_init_type,glorot_uniform
dqn_layer_bias_init_type,zeros
dqn_input_layer_input_nodes,3
dqn_layer_activation_type,relu
dqn_loss_type,mean_squared_error
dqn_optimizer_type,adam
dqn_train_batch_size,10
dqn_train_epochs,150
dqn_hidden_layers_number,3
dqn_dropout_frequency,0.25
dqn_min_samples_needed,365
dqn_samples_to_max_exploitation,3650
dqn_min_exploration_factor,0.1
dqn_max_samples_allowed,1000
roth_erev_experimentation,0.999999
roth_erev_recency,0.6
